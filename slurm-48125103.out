Mon Mar 28 14:58:17 PDT 2022
Starting pipeline
── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──
✔ ggplot2 3.3.5     ✔ purrr   0.3.4
✔ tibble  3.1.6     ✔ dplyr   1.0.7
✔ tidyr   1.1.4     ✔ stringr 1.4.0
✔ readr   2.1.1     ✔ forcats 0.5.1
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
Loading required package: StanHeaders
rstan (Version 2.21.3, GitRev: 2e1f913d3ca3)
For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores()).
To avoid recompilation of unchanged Stan programs, we recommend calling
rstan_options(auto_write = TRUE)

Attaching package: ‘rstan’

The following object is masked from ‘package:tidyr’:

    extract

# A tibble: 26,001 × 9
   estado fecha      positivos_leves positivos_graves negativos_leves
   <chr>  <date>               <int>            <int>           <int>
 1 01     2020-01-01               0                0               0
 2 01     2020-01-03               0                0               0
 3 01     2020-01-04               0                0               0
 4 01     2020-01-05               0                0               1
 5 01     2020-01-06               0                0               1
 6 01     2020-01-07               0                0               0
 7 01     2020-01-08               0                0               1
 8 01     2020-01-09               0                0               2
 9 01     2020-01-10               0                0               1
10 01     2020-01-11               0                0               0
# … with 25,991 more rows, and 4 more variables: negativos_graves <int>,
#   sospechosos_leves <int>, sospechosos_graves <int>, n_pacientes <int>
 [1]   0  15  30  45  60  75  90 135 165 180 195 210 225 240 255 285 300 315 330
[20] 375 390 405 420 435 450 465 480 495 510 525 540 555 570 585 600 615 630 645
[39] 660 675 690 705 720
 [1] 15 15 15 15 15 15 45 30 15 15 15 15 15 15 30 15 15 15 45 15 15 15 15 15 15
[26] 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 15 20
[1] 43

SAMPLING FOR MODEL 'seir' NOW (CHAIN 1).

SAMPLING FOR MODEL 'seir' NOW (CHAIN 2).
Chain 1: 
Chain 1: Gradient evaluation took 0.04 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 400 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 

SAMPLING FOR MODEL 'seir' NOW (CHAIN 3).
Chain 2: 
Chain 2: Gradient evaluation took 0.03 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 300 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 

SAMPLING FOR MODEL 'seir' NOW (CHAIN 4).
Chain 3: 
Chain 3: Gradient evaluation took 0.03 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 300 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 4: 
Chain 4: Gradient evaluation took 0.04 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 400 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 3: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 1: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 2: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 4: Iteration:    1 / 5000 [  0%]  (Warmup)
Chain 1: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 2: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 3: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 4: Iteration:  500 / 5000 [ 10%]  (Warmup)
Chain 1: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 2: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 3: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 4: Iteration: 1000 / 5000 [ 20%]  (Warmup)
Chain 1: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 2: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 3: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 4: Iteration: 1500 / 5000 [ 30%]  (Warmup)
Chain 1: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 2: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 3: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 4: Iteration: 2000 / 5000 [ 40%]  (Warmup)
Chain 1: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 2: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 3: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 4: Iteration: 2500 / 5000 [ 50%]  (Warmup)
Chain 1: Iteration: 3000 / 5000 [ 60%]  (Warmup)
Chain 2: Iteration: 3000 / 5000 [ 60%]  (Warmup)
Chain 3: Iteration: 3000 / 5000 [ 60%]  (Warmup)
Chain 4: Iteration: 3000 / 5000 [ 60%]  (Warmup)
Chain 1: Iteration: 3500 / 5000 [ 70%]  (Warmup)
Chain 2: Iteration: 3500 / 5000 [ 70%]  (Warmup)
Chain 3: Iteration: 3500 / 5000 [ 70%]  (Warmup)
Chain 4: Iteration: 3500 / 5000 [ 70%]  (Warmup)
Chain 1: Iteration: 4000 / 5000 [ 80%]  (Warmup)
Chain 1: Iteration: 4001 / 5000 [ 80%]  (Sampling)
Chain 2: Iteration: 4000 / 5000 [ 80%]  (Warmup)
Chain 2: Iteration: 4001 / 5000 [ 80%]  (Sampling)
Chain 3: Iteration: 4000 / 5000 [ 80%]  (Warmup)
Chain 3: Iteration: 4001 / 5000 [ 80%]  (Sampling)
Chain 4: Iteration: 4000 / 5000 [ 80%]  (Warmup)
Chain 4: Iteration: 4001 / 5000 [ 80%]  (Sampling)
Chain 1: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 2: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 3: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 4: Iteration: 4500 / 5000 [ 90%]  (Sampling)
Chain 1: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 83796.6 seconds (Warm-up)
Chain 1:                21184.8 seconds (Sampling)
Chain 1:                104981 seconds (Total)
Chain 1: 
Chain 2: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 84132.6 seconds (Warm-up)
Chain 2:                21173.7 seconds (Sampling)
Chain 2:                105306 seconds (Total)
Chain 2: 
Chain 3: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 85992.8 seconds (Warm-up)
Chain 3:                22021 seconds (Sampling)
Chain 3:                108014 seconds (Total)
Chain 3: 
Chain 4: Iteration: 5000 / 5000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 86834.4 seconds (Warm-up)
Chain 4:                21712.4 seconds (Sampling)
Chain 4:                108547 seconds (Total)
Chain 4: 
Warning messages:
1: There were 3999 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See
https://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded 
2: Examine the pairs() plot to diagnose sampling problems
 
3: The largest R-hat is 1.09, indicating chains have not mixed.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#r-hat 
4: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#bulk-ess 
5: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.
Running the chains for more iterations may help. See
https://mc-stan.org/misc/warnings.html#tail-ess 
Inference for Stan model: seir.
4 chains, each with iter=5000; warmup=4000; thin=1; 
post-warmup draws per chain=1000, total post-warmup draws=4000.

             mean se_mean   sd  2.5%   25%   50%   75% 97.5% n_eff Rhat
r_betas[1]   0.50    0.00 0.01  0.48  0.49  0.50  0.50  0.51    76 1.06
r_betas[2]   0.35    0.00 0.01  0.32  0.34  0.35  0.36  0.38    69 1.07
r_betas[3]   0.34    0.00 0.01  0.32  0.34  0.34  0.35  0.37    47 1.08
r_betas[4]   0.28    0.00 0.01  0.25  0.27  0.28  0.28  0.30    68 1.06
r_betas[5]   0.25    0.00 0.01  0.23  0.24  0.25  0.26  0.27    98 1.03
r_betas[6]   0.24    0.00 0.01  0.22  0.23  0.24  0.24  0.26   171 1.01
r_betas[7]   0.22    0.00 0.00  0.21  0.21  0.22  0.22  0.22   137 1.03
r_betas[8]   0.18    0.00 0.00  0.18  0.18  0.18  0.19  0.19   118 1.03
r_betas[9]   0.20    0.00 0.01  0.18  0.19  0.20  0.21  0.22    96 1.04
r_betas[10]  0.19    0.00 0.01  0.18  0.19  0.19  0.20  0.21    89 1.05
r_betas[11]  0.21    0.00 0.01  0.19  0.21  0.21  0.22  0.23    98 1.07
r_betas[12]  0.23    0.00 0.01  0.21  0.22  0.23  0.24  0.25   125 1.02
r_betas[13]  0.22    0.00 0.01  0.20  0.21  0.22  0.23  0.24   126 1.01
r_betas[14]  0.24    0.00 0.01  0.22  0.23  0.24  0.24  0.26   135 1.02
r_betas[15]  0.25    0.00 0.01  0.24  0.24  0.25  0.25  0.26   133 1.03
r_betas[16]  0.23    0.00 0.01  0.21  0.22  0.23  0.23  0.25   115 1.04
r_betas[17]  0.26    0.00 0.01  0.24  0.25  0.26  0.27  0.28   136 1.04
r_betas[18]  0.17    0.00 0.01  0.16  0.16  0.17  0.18  0.19   127 1.03
r_betas[19]  0.18    0.00 0.00  0.17  0.18  0.18  0.18  0.18    75 1.07
r_betas[20]  0.20    0.00 0.01  0.18  0.19  0.20  0.20  0.21    58 1.09
r_betas[21]  0.20    0.00 0.01  0.18  0.19  0.20  0.21  0.22    98 1.03
r_betas[22]  0.18    0.00 0.01  0.16  0.17  0.18  0.19  0.20   116 1.02
r_betas[23]  0.20    0.00 0.01  0.18  0.19  0.20  0.20  0.21   148 1.04
r_betas[24]  0.22    0.00 0.01  0.21  0.22  0.22  0.23  0.24   150 1.04
r_betas[25]  0.26    0.00 0.01  0.24  0.25  0.26  0.26  0.28   108 1.02
r_betas[26]  0.31    0.00 0.01  0.29  0.30  0.31  0.32  0.34   105 1.04
r_betas[27]  0.39    0.00 0.01  0.37  0.39  0.40  0.40  0.42   116 1.04
r_betas[28]  0.34    0.00 0.01  0.31  0.33  0.34  0.35  0.36   128 1.02
r_betas[29]  0.24    0.00 0.01  0.22  0.23  0.24  0.24  0.26   159 1.03
r_betas[30]  0.20    0.00 0.01  0.18  0.19  0.20  0.21  0.22   104 1.03
r_betas[31]  0.19    0.00 0.01  0.17  0.18  0.19  0.20  0.21   143 1.01
r_betas[32]  0.19    0.00 0.01  0.17  0.18  0.19  0.20  0.21   124 1.04
r_betas[33]  0.17    0.00 0.01  0.15  0.16  0.17  0.18  0.19    77 1.06
r_betas[34]  0.18    0.00 0.01  0.16  0.17  0.18  0.18  0.19   154 1.03
r_betas[35]  0.21    0.00 0.01  0.19  0.20  0.21  0.22  0.23   160 1.03
r_betas[36]  0.24    0.00 0.01  0.22  0.24  0.24  0.25  0.26   112 1.05
r_betas[37]  0.21    0.00 0.01  0.20  0.21  0.21  0.22  0.24    89 1.05
r_betas[38]  0.28    0.00 0.01  0.25  0.27  0.28  0.28  0.30   152 1.03
r_betas[39]  0.81    0.00 0.02  0.77  0.79  0.81  0.83  0.85   122 1.02
r_betas[40]  0.31    0.00 0.01  0.29  0.30  0.31  0.32  0.34   100 1.04
r_betas[41]  0.12    0.00 0.01  0.10  0.11  0.12  0.12  0.13    86 1.05
r_betas[42]  0.10    0.00 0.01  0.09  0.10  0.10  0.10  0.11   171 1.03
r_betas[43]  0.12    0.00 0.01  0.10  0.11  0.12  0.12  0.13   156 1.02
phi         36.43    0.16 1.92 32.90 35.01 36.38 37.79 40.28   145 1.02

Samples were drawn using NUTS(diag_e) at Tue Mar 29 21:18:28 2022.
For each parameter, n_eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor on split chains (at 
convergence, Rhat=1).
           S            E            I            R            t 
9.999680e-01 1.601036e-05 1.601036e-05 0.000000e+00 0.000000e+00 
# A tibble: 800 × 14
   fecha_estimacion fecha      nuevos_mu_10 nuevos_mu_50 nuevos_mu_90 acum_mu_10
   <date>           <date>            <dbl>        <dbl>        <dbl>      <dbl>
 1 2022-03-29       2020-03-01        2046         2046         2046       2046 
 2 2022-03-29       2020-03-02         451.         454.         456.      2497.
 3 2022-03-29       2020-03-03         551.         557.         565.      3049.
 4 2022-03-29       2020-03-04         644.         654.         667.      3693.
 5 2022-03-29       2020-03-05         736.         751.         770.      4429.
 6 2022-03-29       2020-03-06         832.         852.         877.      5261.
 7 2022-03-29       2020-03-07         935.         960.         994.      6196.
 8 2022-03-29       2020-03-08        1048.        1080.        1123.      7244.
 9 2022-03-29       2020-03-09        1172.        1212.        1266.      8417.
10 2022-03-29       2020-03-10        1310.        1359.        1426.      9726.
# … with 790 more rows, and 8 more variables: acum_mu_50 <dbl>,
#   acum_mu_90 <dbl>, nuevos_obs_10 <int>, nuevos_obs_50 <dbl>,
#   nuevos_obs_90 <int>, acum_obs_10 <int>, acum_obs_50 <dbl>,
#   acum_obs_90 <int>
Rows: 800 Columns: 14
── Column specification ────────────────────────────────────────────────────────
Delimiter: ","
dbl  (12): nuevos_mu_10, nuevos_mu_50, nuevos_mu_90, acum_mu_10, acum_mu_50,...
date  (2): fecha_estimacion, fecha

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
Warning messages:
1: Removed 3 rows containing missing values (position_stack). 
2: Removed 19 row(s) containing missing values (geom_path). 
3: Removed 740 row(s) containing missing values (geom_path). 
Pipeline finished
Tue Mar 29 21:25:35 PDT 2022

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este código está basado el código del repositorio https://github.com/k-sys/covid-19\n",
    "# Este repositorio fue clonado el 2020-04-25 en https://github.com/coronamex/covid-20\n",
    "# Tiene pequeñas modificaciones para realizar estimaciones con los datos de México distribuidos\n",
    "# a través de CoronaMex.\n",
    "# El código tomado de https://github.com/k-sys/covid-19 está en el dominito público.\n",
    "# El resto se distribuye con una licencia GPL-3\n",
    "\n",
    "# (C) Copyright 2020 Sur Herrera Paredes\n",
    "\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "# For some reason Theano is unhappy when I run the GP, need to disable future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pymc3 as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "import arviz\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import ticker\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirmed_to_onset(confirmed, p_delay):\n",
    "\n",
    "    assert not confirmed.isna().any()\n",
    "    \n",
    "    # Reverse cases so that we convolve into the past\n",
    "    convolved = np.convolve(confirmed[::-1].values, p_delay)\n",
    "\n",
    "    # Calculate the new date range\n",
    "    dr = pd.date_range(end=confirmed.index[-1],\n",
    "                       periods=len(convolved))\n",
    "\n",
    "    # Flip the values and assign the date range\n",
    "    onset = pd.Series(np.flip(convolved), index=dr)\n",
    "    \n",
    "    return onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_onset_for_right_censorship(onset, p_delay):\n",
    "    cumulative_p_delay = p_delay.cumsum()\n",
    "    \n",
    "    # Calculate the additional ones needed so shapes match\n",
    "    ones_needed = len(onset) - len(cumulative_p_delay)\n",
    "    padding_shape = (0, ones_needed)\n",
    "    \n",
    "    # Add ones and flip back\n",
    "    cumulative_p_delay = np.pad(\n",
    "        cumulative_p_delay,\n",
    "        padding_shape,\n",
    "        constant_values=1)\n",
    "    cumulative_p_delay = np.flip(cumulative_p_delay)\n",
    "    \n",
    "    # Adjusts observed onset values to expected terminal onset values\n",
    "    adjusted = onset / cumulative_p_delay\n",
    "    \n",
    "    return adjusted, cumulative_p_delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMCModel(object):\n",
    "    \n",
    "    def __init__(self, region, onset, cumulative_p_delay, window=50):\n",
    "        \n",
    "        # Just for identification purposes\n",
    "        self.region = region\n",
    "        \n",
    "        # For the model, we'll only look at the last N\n",
    "        self.onset = onset.iloc[-window:]\n",
    "        self.cumulative_p_delay = cumulative_p_delay[-window:]\n",
    "        \n",
    "        # Where we store the results\n",
    "        self.trace = None\n",
    "        self.trace_index = self.onset.index[1:]\n",
    "\n",
    "    # def run(self, chains=1, tune=3000, draws=1000, target_accept=.95):\n",
    "    def run(self, chains=3, tune=1000, draws=1000, target_accept=.95):\n",
    "\n",
    "        with pm.Model() as model:\n",
    "\n",
    "            # Random walk magnitude\n",
    "            step_size = pm.HalfNormal('step_size', sigma=.03)\n",
    "\n",
    "            # Theta random walk\n",
    "            theta_raw_init = pm.Normal('theta_raw_init', 0.1, 0.1)\n",
    "            theta_raw_steps = pm.Normal('theta_raw_steps', shape=len(self.onset)-2) * step_size\n",
    "            theta_raw = tt.concatenate([[theta_raw_init], theta_raw_steps])\n",
    "            theta = pm.Deterministic('theta', theta_raw.cumsum())\n",
    "\n",
    "            # Let the serial interval be a random variable and calculate r_t\n",
    "            serial_interval = pm.Gamma('serial_interval', alpha=6, beta=1.5)\n",
    "            gamma = 1.0 / serial_interval\n",
    "            r_t = pm.Deterministic('r_t', theta/gamma + 1)\n",
    "\n",
    "            inferred_yesterday = self.onset.values[:-1] / self.cumulative_p_delay[:-1]\n",
    "            \n",
    "            expected_today = inferred_yesterday * self.cumulative_p_delay[1:] * pm.math.exp(theta)\n",
    "\n",
    "            # Ensure cases stay above zero for poisson\n",
    "            mu = pm.math.maximum(.1, expected_today)\n",
    "            observed = self.onset.round().values[1:]\n",
    "            cases = pm.Poisson('cases', mu=mu, observed=observed)\n",
    "\n",
    "            self.trace = pm.sample(\n",
    "                chains=chains,\n",
    "                tune=tune,\n",
    "                draws=draws,\n",
    "                target_accept=target_accept)\n",
    "            \n",
    "            return self\n",
    "    \n",
    "    def run_gp(self):\n",
    "        with pm.Model() as model:\n",
    "            gp_shape = len(self.onset) - 1\n",
    "\n",
    "            length_scale = pm.Gamma(\"length_scale\", alpha=3, beta=.4)\n",
    "\n",
    "            eta = .05\n",
    "            cov_func = eta**2 * pm.gp.cov.ExpQuad(1, length_scale)\n",
    "\n",
    "            gp = pm.gp.Latent(mean_func=pm.gp.mean.Constant(c=0), \n",
    "                              cov_func=cov_func)\n",
    "\n",
    "            # Place a GP prior over the function f.\n",
    "            theta = gp.prior(\"theta\", X=np.arange(gp_shape)[:, None])\n",
    "\n",
    "            # Let the serial interval be a random variable and calculate r_t\n",
    "            serial_interval = pm.Gamma('serial_interval', alpha=6, beta=1.5)\n",
    "            gamma = 1.0 / serial_interval\n",
    "            r_t = pm.Deterministic('r_t', theta / gamma + 1)\n",
    "\n",
    "            inferred_yesterday = self.onset.values[:-1] / self.cumulative_p_delay[:-1]\n",
    "            expected_today = inferred_yesterday * self.cumulative_p_delay[1:] * pm.math.exp(theta)\n",
    "\n",
    "            # Ensure cases stay above zero for poisson\n",
    "            mu = pm.math.maximum(.1, expected_today)\n",
    "            observed = self.onset.round().values[1:]\n",
    "            cases = pm.Poisson('cases', mu=mu, observed=observed)\n",
    "\n",
    "            self.trace = pm.sample(chains=1, tune=1000, draws=1000, target_accept=.8)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_model(model):\n",
    "    \n",
    "    r_t = model.trace['r_t']\n",
    "    mean = np.mean(r_t, axis=0)\n",
    "    median = np.median(r_t, axis=0)\n",
    "    # hpd_90 = pm.stats.hpd(r_t, credible_interval=.9)\n",
    "    # hpd_50 = pm.stats.hpd(r_t, credible_interval=.5)\n",
    "    hpd_90 = arviz.hdi(r_t, hdi_prob = 0.9)\n",
    "    hpd_50 = arviz.hdi(r_t, hdi_prob = 0.5)\n",
    "    \n",
    "    idx = pd.MultiIndex.from_product([\n",
    "            [model.region],\n",
    "            model.trace_index\n",
    "        ], names=['region', 'date'])\n",
    "        \n",
    "    df = pd.DataFrame(data=np.c_[mean, median, hpd_90, hpd_50], index=idx,\n",
    "                 columns=['mean', 'median', 'lower_90', 'upper_90', 'lower_50','upper_50'])\n",
    "    return df\n",
    "\n",
    "def create_and_run_model(name, state):\n",
    "    confirmed = state.positive.diff().dropna()\n",
    "    onset = confirmed_to_onset(confirmed, p_delay)\n",
    "    adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset, p_delay)\n",
    "    return MCMCModel(name, onset, cumulative_p_delay).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_p_retraso(serie_sintomas, serie_confirmacion):\n",
    "    \"\"\"Calcular distribución en retraso entre día de inicio de síntomas\n",
    "    y confirmación de un caso.\"\"\"\n",
    "    \n",
    "    # serie_sintomas = \"../../datos/datos_abiertos/serie_tiempo_nacional_confirmados.csv\"\n",
    "    # serie_confirmacion = \"../../datos/datos_abiertos/serie_tiempo_nacional_fecha_confirmacion.csv\"\n",
    "    \n",
    "    # Leer tablas\n",
    "    Dat_sintomas = pd.read_csv(serie_sintomas)\n",
    "    Dat_sintomas.head()\n",
    "    Dat_confirmacion = pd.read_csv(serie_confirmacion)\n",
    "    Dat_confirmacion.head()\n",
    "    Dat_sintomas = Dat_sintomas[['fecha', 'sintomas_acumulados']]\n",
    "    Dat_confirmacion = Dat_confirmacion[['fecha', 'casos_acumulados']]\n",
    "    \n",
    "    # Unir tablas\n",
    "    Dat = pd.concat([Dat_sintomas.set_index('fecha'), Dat_confirmacion.set_index('fecha')], axis=1, sort=False).reset_index(col_fill = 'fecha')\n",
    "    Dat.columns = ['fecha', 'sintomas_acumulados', 'casos_acumulados']\n",
    "    Dat = Dat.fillna(0)\n",
    "    # Dat['dif'] = Dat.sintomas_acumulados - Dat.casos_acumulados\n",
    "    Dat.fecha = pd.to_datetime(Dat.fecha)\n",
    "    # Dat\n",
    "    \n",
    "    # Preparar serie vacía\n",
    "    dias = (pd.Series(max(Dat.fecha)) - pd.Series(min(Dat.fecha))).dt.days[0]\n",
    "    p_retraso = pd.Series(np.zeros(dias))\n",
    "    for i, fila in Dat.iterrows():\n",
    "        for j in range(i, Dat.shape[0]):\n",
    "            # print(i, j)\n",
    "            if Dat.casos_acumulados[j] >= Dat.sintomas_acumulados[i]:\n",
    "                # print(\"hola\")\n",
    "                # Sumar casos retrasados n dias\n",
    "                if i == 0:\n",
    "                    nuevos = Dat.sintomas_acumulados[i]\n",
    "                else:\n",
    "                    nuevos = Dat.sintomas_acumulados[i] - Dat.sintomas_acumulados[i - 1]\n",
    "                # nuevos = abs(Dat.sintomas_acumulados[i] - Dat.casos_acumulados[j])\n",
    "                p_retraso[j - i] = p_retraso[j - i] + nuevos\n",
    "                break\n",
    "    \n",
    "    # Calcular prob\n",
    "    # p_retraso.sum()\n",
    "    p_retraso = p_retraso / p_retraso.sum()\n",
    "    # print(p_retraso.to_string())\n",
    "    \n",
    "    # Limpiar\n",
    "    ii = p_retraso > 0\n",
    "    ii_max = np.max(p_retraso.index[ii])\n",
    "    p_retraso = p_retraso[0:ii_max]\n",
    "\n",
    "    return p_retraso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular p_retraso\n",
    "# serie_sintomas_nacional = \"../../datos/datos_abiertos/serie_tiempo_nacional_confirmados.csv.gz\"\n",
    "# serie_confirmacion_nacional = \"../../datos/datos_abiertos/serie_tiempo_nacional_fecha_confirmacion.csv.gz\"\n",
    "# serie_confirmacion_estados = \"../../datos/datos_abiertos/serie_tiempo_estados_fecha_confirmacion.csv.gz\"\n",
    "# dir_estimado = \"../estimados/\"\n",
    "\n",
    "serie_sintomas_nacional = \"../datos/datos_abiertos/serie_tiempo_nacional_confirmados.csv.gz\"\n",
    "serie_confirmacion_nacional = \"../datos/datos_abiertos/serie_tiempo_nacional_fecha_confirmacion.csv.gz\"\n",
    "serie_confirmacion_estados = \"../datos/datos_abiertos/serie_tiempo_estados_fecha_confirmacion.csv.gz\"\n",
    "dir_estimado = \"estimados/\"\n",
    "\n",
    "print(\"Parámetros leídos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular retraso deteccción\n",
    "p_retraso = calcular_p_retraso(serie_sintomas=serie_sintomas_nacional, serie_confirmacion=serie_confirmacion_nacional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer serie de tiempo estados confirmacón\n",
    "Dat = pd.read_csv(serie_confirmacion_estados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ent = \"Ciudad de México\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = {}\n",
    "for ent in Dat.estado.unique():\n",
    "    casos = Dat[ Dat.estado == ent ]\n",
    "    casos = casos[['fecha', 'casos_nuevos_um']]\n",
    "    casos.columns = ['date', 'positives']\n",
    "    casos = casos.set_index('date')\n",
    "    \n",
    "    if casos.positives.sum() > 500:\n",
    "        print(ent)\n",
    "        # Suavizar y luego correr por estado\n",
    "        casos = casos.rolling(window=7, center = True).mean()\n",
    "        casos = casos[~casos.isin([np.nan]).positives]\n",
    "        \n",
    "        # Ajustar\n",
    "        inicio = confirmed_to_onset(casos.positives, p_retraso)\n",
    "        ajustados, p_retraso_acumulado = adjust_onset_for_right_censorship(inicio, p_retraso)\n",
    "        \n",
    "        # Correr modelo\n",
    "        ii = ajustados.isin([np.nan, np.inf,-np.inf])\n",
    "        p_retraso_acumulado = p_retraso_acumulado[~ii]\n",
    "        m1 = MCMCModel(ent, inicio[~ii], p_retraso_acumulado, window=100).run()\n",
    "        \n",
    "        modelos[ent] = m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar tablas\n",
    "Tab = pd.DataFrame()\n",
    "for k in modelos.keys():\n",
    "    print(k)\n",
    "    m1 = modelos[k]\n",
    "    tab = df_from_model(m1)\n",
    "    tab = tab.droplevel(0)\n",
    "    tab = tab.reset_index()\n",
    "    tab['estado'] = k\n",
    "    \n",
    "    Tab = pd.concat([Tab, tab])\n",
    "Tab['fecha_estimado'] = date.today().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = dir_estimado + '/rt_live_estimados.csv'\n",
    "Tab.to_csv(archivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

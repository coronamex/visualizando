{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este código está basado el código del repositorio https://github.com/k-sys/covid-19\n",
    "# Este repositorio fue clonado el 2020-04-25 en https://github.com/coronamex/covid-20\n",
    "# Tiene pequeñas modificaciones para realizar estimaciones con los datos de México distribuidos\n",
    "# a través de CoronaMex.\n",
    "# El código tomado de https://github.com/k-sys/covid-19 está en el dominito público.\n",
    "# El resto se distribuye con una licencia GPL-3\n",
    "\n",
    "# (C) Copyright 2020 Sur Herrera Paredes\n",
    "\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "\n",
    "# For some reason Theano is unhappy when I run the GP, need to disable future warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pymc3 as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import ticker\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirmed_to_onset(confirmed, p_delay):\n",
    "\n",
    "    assert not confirmed.isna().any()\n",
    "    \n",
    "    # Reverse cases so that we convolve into the past\n",
    "    convolved = np.convolve(confirmed[::-1].values, p_delay)\n",
    "\n",
    "    # Calculate the new date range\n",
    "    dr = pd.date_range(end=confirmed.index[-1],\n",
    "                       periods=len(convolved))\n",
    "\n",
    "    # Flip the values and assign the date range\n",
    "    onset = pd.Series(np.flip(convolved), index=dr)\n",
    "    \n",
    "    return onset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_onset_for_right_censorship(onset, p_delay):\n",
    "    cumulative_p_delay = p_delay.cumsum()\n",
    "    \n",
    "    # Calculate the additional ones needed so shapes match\n",
    "    ones_needed = len(onset) - len(cumulative_p_delay)\n",
    "    padding_shape = (0, ones_needed)\n",
    "    \n",
    "    # Add ones and flip back\n",
    "    cumulative_p_delay = np.pad(\n",
    "        cumulative_p_delay,\n",
    "        padding_shape,\n",
    "        constant_values=1)\n",
    "    cumulative_p_delay = np.flip(cumulative_p_delay)\n",
    "    \n",
    "    # Adjusts observed onset values to expected terminal onset values\n",
    "    adjusted = onset / cumulative_p_delay\n",
    "    \n",
    "    return adjusted, cumulative_p_delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMCModel(object):\n",
    "    \n",
    "    def __init__(self, region, onset, cumulative_p_delay, window=50):\n",
    "        \n",
    "        # Just for identification purposes\n",
    "        self.region = region\n",
    "        \n",
    "        # For the model, we'll only look at the last N\n",
    "        self.onset = onset.iloc[-window:]\n",
    "        self.cumulative_p_delay = cumulative_p_delay[-window:]\n",
    "        \n",
    "        # Where we store the results\n",
    "        self.trace = None\n",
    "        self.trace_index = self.onset.index[1:]\n",
    "\n",
    "    def run(self, chains=1, tune=3000, draws=1000, target_accept=.95):\n",
    "\n",
    "        with pm.Model() as model:\n",
    "\n",
    "            # Random walk magnitude\n",
    "            step_size = pm.HalfNormal('step_size', sigma=.03)\n",
    "\n",
    "            # Theta random walk\n",
    "            theta_raw_init = pm.Normal('theta_raw_init', 0.1, 0.1)\n",
    "            theta_raw_steps = pm.Normal('theta_raw_steps', shape=len(self.onset)-2) * step_size\n",
    "            theta_raw = tt.concatenate([[theta_raw_init], theta_raw_steps])\n",
    "            theta = pm.Deterministic('theta', theta_raw.cumsum())\n",
    "\n",
    "            # Let the serial interval be a random variable and calculate r_t\n",
    "            serial_interval = pm.Gamma('serial_interval', alpha=6, beta=1.5)\n",
    "            gamma = 1.0 / serial_interval\n",
    "            r_t = pm.Deterministic('r_t', theta/gamma + 1)\n",
    "\n",
    "            inferred_yesterday = self.onset.values[:-1] / self.cumulative_p_delay[:-1]\n",
    "            \n",
    "            expected_today = inferred_yesterday * self.cumulative_p_delay[1:] * pm.math.exp(theta)\n",
    "\n",
    "            # Ensure cases stay above zero for poisson\n",
    "            mu = pm.math.maximum(.1, expected_today)\n",
    "            observed = self.onset.round().values[1:]\n",
    "            cases = pm.Poisson('cases', mu=mu, observed=observed)\n",
    "\n",
    "            self.trace = pm.sample(\n",
    "                chains=chains,\n",
    "                tune=tune,\n",
    "                draws=draws,\n",
    "                target_accept=target_accept)\n",
    "            \n",
    "            return self\n",
    "    \n",
    "    def run_gp(self):\n",
    "        with pm.Model() as model:\n",
    "            gp_shape = len(self.onset) - 1\n",
    "\n",
    "            length_scale = pm.Gamma(\"length_scale\", alpha=3, beta=.4)\n",
    "\n",
    "            eta = .05\n",
    "            cov_func = eta**2 * pm.gp.cov.ExpQuad(1, length_scale)\n",
    "\n",
    "            gp = pm.gp.Latent(mean_func=pm.gp.mean.Constant(c=0), \n",
    "                              cov_func=cov_func)\n",
    "\n",
    "            # Place a GP prior over the function f.\n",
    "            theta = gp.prior(\"theta\", X=np.arange(gp_shape)[:, None])\n",
    "\n",
    "            # Let the serial interval be a random variable and calculate r_t\n",
    "            serial_interval = pm.Gamma('serial_interval', alpha=6, beta=1.5)\n",
    "            gamma = 1.0 / serial_interval\n",
    "            r_t = pm.Deterministic('r_t', theta / gamma + 1)\n",
    "\n",
    "            inferred_yesterday = self.onset.values[:-1] / self.cumulative_p_delay[:-1]\n",
    "            expected_today = inferred_yesterday * self.cumulative_p_delay[1:] * pm.math.exp(theta)\n",
    "\n",
    "            # Ensure cases stay above zero for poisson\n",
    "            mu = pm.math.maximum(.1, expected_today)\n",
    "            observed = self.onset.round().values[1:]\n",
    "            cases = pm.Poisson('cases', mu=mu, observed=observed)\n",
    "\n",
    "            self.trace = pm.sample(chains=1, tune=1000, draws=1000, target_accept=.8)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_from_model(model):\n",
    "    \n",
    "    r_t = model.trace['r_t']\n",
    "    mean = np.mean(r_t, axis=0)\n",
    "    median = np.median(r_t, axis=0)\n",
    "    hpd_90 = pm.stats.hpd(r_t, credible_interval=.9)\n",
    "    hpd_50 = pm.stats.hpd(r_t, credible_interval=.5)\n",
    "    \n",
    "    idx = pd.MultiIndex.from_product([\n",
    "            [model.region],\n",
    "            model.trace_index\n",
    "        ], names=['region', 'date'])\n",
    "        \n",
    "    df = pd.DataFrame(data=np.c_[mean, median, hpd_90, hpd_50], index=idx,\n",
    "                 columns=['mean', 'median', 'lower_90', 'upper_90', 'lower_50','upper_50'])\n",
    "    return df\n",
    "\n",
    "def create_and_run_model(name, state):\n",
    "    confirmed = state.positive.diff().dropna()\n",
    "    onset = confirmed_to_onset(confirmed, p_delay)\n",
    "    adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset, p_delay)\n",
    "    return MCMCModel(name, onset, cumulative_p_delay).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_p_retraso(serie_sintomas, serie_confirmacion):\n",
    "    \"\"\"Calcular distribución en retraso entre día de inicio de síntomas\n",
    "    y confirmación de un caso.\"\"\"\n",
    "    \n",
    "    # serie_sintomas = \"../../datos/datos_abiertos/serie_tiempo_nacional_confirmados.csv\"\n",
    "    # serie_confirmacion = \"../../datos/datos_abiertos/serie_tiempo_nacional_fecha_confirmacion.csv\"\n",
    "    \n",
    "    # Leer tablas\n",
    "    Dat_sintomas = pd.read_csv(serie_sintomas)\n",
    "    Dat_sintomas.head()\n",
    "    Dat_confirmacion = pd.read_csv(serie_confirmacion)\n",
    "    Dat_confirmacion.head()\n",
    "    Dat_sintomas = Dat_sintomas[['fecha', 'sintomas_acumulados']]\n",
    "    Dat_confirmacion = Dat_confirmacion[['fecha', 'casos_acumulados']]\n",
    "    \n",
    "    # Unir tablas\n",
    "    Dat = pd.concat([Dat_sintomas.set_index('fecha'), Dat_confirmacion.set_index('fecha')], axis=1, sort=False).reset_index(col_fill = 'fecha')\n",
    "    Dat.columns = ['fecha', 'sintomas_acumulados', 'casos_acumulados']\n",
    "    Dat = Dat.fillna(0)\n",
    "    # Dat['dif'] = Dat.sintomas_acumulados - Dat.casos_acumulados\n",
    "    Dat.fecha = pd.to_datetime(Dat.fecha)\n",
    "    # Dat\n",
    "    \n",
    "    # Preparar serie vacía\n",
    "    dias = (pd.Series(max(Dat.fecha)) - pd.Series(min(Dat.fecha))).dt.days[0]\n",
    "    p_retraso = pd.Series(np.zeros(dias))\n",
    "    for i, fila in Dat.iterrows():\n",
    "        for j in range(i, Dat.shape[0]):\n",
    "            # print(i, j)\n",
    "            if Dat.casos_acumulados[j] >= Dat.sintomas_acumulados[i]:\n",
    "                # print(\"hola\")\n",
    "                # Sumar casos retrasados n dias\n",
    "                p_retraso[j - i] = p_retraso[j - i] + abs(Dat.sintomas_acumulados[i] - Dat.casos_acumulados[j])\n",
    "                break\n",
    "    \n",
    "    # Calcular prob\n",
    "    # p_retraso.sum()\n",
    "    p_retraso = p_retraso / p_retraso.sum()\n",
    "    # print(p_retraso.to_string())\n",
    "    \n",
    "    # Limpiar\n",
    "    ii = p_retraso > 0\n",
    "    ii_max = np.max(p_retraso.index[ii])\n",
    "    p_retraso = p_retraso[0:ii_max]\n",
    "\n",
    "    return p_retraso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://covidtracking.com/api/v1/states/daily.csv'\n",
    "# states = pd.read_csv(url,\n",
    "#                      parse_dates=['date'],\n",
    "#                      index_col=['state', 'date']).sort_index()\n",
    "\n",
    "# # Note: GU/AS/VI do not have enough data for this model to run\n",
    "# # Note: PR had -384 change recently in total count so unable to model\n",
    "# states = states.drop(['MP', 'GU', 'AS', 'PR', 'VI'])\n",
    "\n",
    "# ## SUR\n",
    "# states = {state: grp for state, grp in states.groupby('state')}['CA']\n",
    "# states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make sure that all the states have current data\n",
    "# today = datetime.combine(date.today(), datetime.min.time())\n",
    "# last_updated = states.reset_index('date').groupby('state')['date'].max()\n",
    "# is_current = last_updated < today\n",
    "\n",
    "# try:\n",
    "#     assert is_current.sum() == 0\n",
    "# except AssertionError:\n",
    "#     print(\"Not all states have updated\")\n",
    "#     display(last_updated[is_current])\n",
    "\n",
    "# # Ensure all case diffs are greater than zero\n",
    "# for state, grp in states.groupby('state'):\n",
    "#     new_cases = grp.positive.diff().dropna()\n",
    "#     is_positive = new_cases.ge(0)\n",
    "    \n",
    "#     try:\n",
    "#         assert is_positive.all()\n",
    "#     except AssertionError:\n",
    "#         print(f\"Warning: {state} has date with negative case counts\")\n",
    "#         display(new_cases[~is_positive])\n",
    "        \n",
    "# # Let's make sure that states have added cases\n",
    "# idx = pd.IndexSlice\n",
    "# assert not states.loc[idx[:, '2020-04-22':'2020-04-23'], 'positive'].groupby('state').diff().dropna().eq(0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the patient CSV\n",
    "# patients = pd.read_csv(\n",
    "#     '../../COVID-20/data/linelist.csv',\n",
    "#     parse_dates=False,\n",
    "#     usecols=[\n",
    "#         'date_confirmation',\n",
    "#         'date_onset_symptoms'],\n",
    "#     low_memory=False)\n",
    "\n",
    "# patients.columns = ['Onset', 'Confirmed']\n",
    "\n",
    "# # There's an errant reversed date\n",
    "# patients = patients.replace('01.31.2020', '31.01.2020')\n",
    "\n",
    "# # Only keep if both values are present\n",
    "# patients = patients.dropna()\n",
    "\n",
    "# # Must have strings that look like individual dates\n",
    "# # \"2020.03.09\" is 10 chars long\n",
    "# is_ten_char = lambda x: x.str.len().eq(10)\n",
    "# patients = patients[is_ten_char(patients.Confirmed) & \n",
    "#                     is_ten_char(patients.Onset)]\n",
    "\n",
    "# # Convert both to datetimes\n",
    "# patients.Confirmed = pd.to_datetime(\n",
    "#     patients.Confirmed, format='%d.%m.%Y')\n",
    "# patients.Onset = pd.to_datetime(\n",
    "#     patients.Onset, format='%d.%m.%Y')\n",
    "\n",
    "# # Only keep records where confirmed > onset\n",
    "# patients = patients[patients.Confirmed >= patients.Onset]\n",
    "\n",
    "# ## SUR\n",
    "# patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the delta in days between onset and confirmation\n",
    "# delay = (patients.Confirmed - patients.Onset).dt.days\n",
    "\n",
    "# # Convert samples to an empirical distribution\n",
    "# p_delay = delay.value_counts().sort_index()\n",
    "# new_range = np.arange(0, p_delay.index.max()+1)\n",
    "# p_delay = p_delay.reindex(new_range, fill_value=0)\n",
    "# p_delay /= p_delay.sum()\n",
    "\n",
    "# # Show our work\n",
    "# fig, axes = plt.subplots(ncols=2, figsize=(9,3))\n",
    "# p_delay.plot(title='P(Delay)', ax=axes[0])\n",
    "# p_delay.cumsum().plot(title='P(Delay <= x)', ax=axes[1])\n",
    "# for ax in axes:\n",
    "#     ax.set_xlabel('days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state = 'CA'\n",
    "# confirmed = states.xs(state).positive.diff().dropna()\n",
    "# onset = confirmed_to_onset(confirmed, p_delay)\n",
    "# ## SUR\n",
    "# onset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset, p_delay)\n",
    "\n",
    "# ## SUR\n",
    "# print(adjusted.head())\n",
    "# cumulative_p_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = {}\n",
    "\n",
    "# for state, grp in states.groupby('state'):\n",
    "    \n",
    "#     print(state)\n",
    "    \n",
    "#     if state in models:\n",
    "#         print(f'Skipping {state}, already in cache')\n",
    "#         continue\n",
    "    \n",
    "#     models[state] = create_and_run_model(state, grp.droplevel(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = 'CA'\n",
    "# confirmed = states.positive.diff().dropna()\n",
    "# # confirmed = state.positive.diff().dropna()\n",
    "# confirmed = confirmed.droplevel(0)\n",
    "# # confirmed\n",
    "# onset = confirmed_to_onset(confirmed, p_delay)\n",
    "# # confirmed_to_onset(confirmed, p_delay)\n",
    "# adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset, p_delay)\n",
    "# # adjust_onset_for_right_censorship(onset, p_delay)\n",
    "# m1 = MCMCModel(name, onset, cumulative_p_delay).run()\n",
    "# m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular p_retraso\n",
    "# serie_sintomas_nacional = \"../../datos/datos_abiertos/serie_tiempo_nacional_confirmados.csv\"\n",
    "# serie_confirmacion_nacional = \"../../datos/datos_abiertos/serie_tiempo_nacional_fecha_confirmacion.csv\"\n",
    "# serie_confirmacion_estados = \"../../datos/datos_abiertos/serie_tiempo_estados_fecha_confirmacion.csv\"\n",
    "# dir_estimado = \"../estimados/\"\n",
    "\n",
    "serie_sintomas_nacional = \"../datos/datos_abiertos/serie_tiempo_nacional_confirmados.csv\"\n",
    "serie_confirmacion_nacional = \"../datos/datos_abiertos/serie_tiempo_nacional_fecha_confirmacion.csv\"\n",
    "serie_confirmacion_estados = \"../datos/datos_abiertos/serie_tiempo_estados_fecha_confirmacion.csv\"\n",
    "dir_estimado = \"estimados/\"\n",
    "\n",
    "print(\"Parámetros leídos\")\n",
    "p_retraso = calcular_p_retraso(serie_sintomas=serie_sintomas_nacional, serie_confirmacion=serie_confirmacion_nacional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sintomas = pd.read_csv(serie_sintomas)\n",
    "# sintomas = sintomas[['fecha', 'sintomas_nuevos']]\n",
    "# sintomas.columns = ['date', 'positives']\n",
    "# sintomas = sintomas.set_index('date')\n",
    "# sintomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Leer serie de casos confirmados\n",
    "# casos = pd.read_csv(serie_confirmacion_estados)\n",
    "# casos = casos[['fecha', 'casos_nuevos']]\n",
    "# casos.columns = ['date', 'positives']\n",
    "# casos = casos.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estado</th>\n",
       "      <th>fecha</th>\n",
       "      <th>casos_acumulados_um</th>\n",
       "      <th>casos_acumulados_res</th>\n",
       "      <th>muertes_acumuladas_um</th>\n",
       "      <th>muertes_acumuladas_res</th>\n",
       "      <th>casos_nuevos_um</th>\n",
       "      <th>casos_nuevos_res</th>\n",
       "      <th>muertes_nuevas_um</th>\n",
       "      <th>muertes_nuevas_res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>2020-03-16</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>2020-03-17</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>2020-03-18</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>2020-03-19</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           estado       fecha  casos_acumulados_um  casos_acumulados_res  \\\n",
       "0  Aguascalientes  2020-03-15                    1                   NaN   \n",
       "1  Aguascalientes  2020-03-16                    1                   NaN   \n",
       "2  Aguascalientes  2020-03-17                    1                   NaN   \n",
       "3  Aguascalientes  2020-03-18                    1                   NaN   \n",
       "4  Aguascalientes  2020-03-19                    4                   NaN   \n",
       "\n",
       "   muertes_acumuladas_um  muertes_acumuladas_res  casos_nuevos_um  \\\n",
       "0                      0                     NaN                1   \n",
       "1                      0                     NaN                0   \n",
       "2                      0                     NaN                0   \n",
       "3                      0                     NaN                0   \n",
       "4                      0                     NaN                3   \n",
       "\n",
       "   casos_nuevos_res  muertes_nuevas_um  muertes_nuevas_res  \n",
       "0               NaN                  0                 NaN  \n",
       "1               NaN                  0                 NaN  \n",
       "2               NaN                  0                 NaN  \n",
       "3               NaN                  0                 NaN  \n",
       "4               NaN                  0                 NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dat = pd.read_csv(serie_confirmacion_estados)\n",
    "Dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [serial_interval, theta_raw_steps, theta_raw_init, step_size]\n",
      "Sampling chain 0, 0 divergences: 100%|██████████| 4000/4000 [00:46<00:00, 86.54it/s] \n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [serial_interval, theta_raw_steps, theta_raw_init, step_size]\n",
      "Sampling chain 0, 0 divergences: 100%|██████████| 4000/4000 [01:58<00:00, 33.85it/s]\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [serial_interval, theta_raw_steps, theta_raw_init, step_size]\n",
      "Sampling chain 0, 0 divergences: 100%|██████████| 4000/4000 [00:43<00:00, 92.35it/s] \n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [serial_interval, theta_raw_steps, theta_raw_init, step_size]\n",
      "Sampling chain 0, 0 divergences: 100%|██████████| 4000/4000 [00:22<00:00, 179.46it/s]\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [serial_interval, theta_raw_steps, theta_raw_init, step_size]\n",
      "Sampling chain 0, 0 divergences: 100%|██████████| 4000/4000 [00:25<00:00, 159.27it/s]\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Sequential sampling (1 chains in 1 job)\n",
      "NUTS: [serial_interval, theta_raw_steps, theta_raw_init, step_size]\n",
      "Sampling chain 0, 0 divergences: 100%|██████████| 4000/4000 [00:25<00:00, 157.53it/s]\n",
      "Only one chain was sampled, this makes it impossible to run some convergence checks\n"
     ]
    }
   ],
   "source": [
    "modelos = {}\n",
    "for ent in Dat.estado.unique():\n",
    "    casos = Dat[ Dat.estado == ent ]\n",
    "    casos = casos[['fecha', 'casos_nuevos_um']]\n",
    "    casos.columns = ['date', 'positives']\n",
    "    casos = casos.set_index('date')\n",
    "    \n",
    "    if casos.positives.sum() > 500:\n",
    "        print(ent)\n",
    "        inicio = confirmed_to_onset(casos.positives, p_retraso)\n",
    "        ajustados, p_retraso_acumulado = adjust_onset_for_right_censorship(inicio, p_retraso)\n",
    "        ii = ajustados.isin([np.nan, np.inf,-np.inf])\n",
    "        p_retraso_acumulado = p_retraso_acumulado[~ii]\n",
    "        m1 = MCMCModel(ent, inicio[~ii], p_retraso_acumulado).run()\n",
    "        \n",
    "        modelos[ent] = m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Baja California': <__main__.MCMCModel at 0x7f747a860550>,\n",
       " 'Ciudad de México': <__main__.MCMCModel at 0x7f747a860b70>,\n",
       " 'México': <__main__.MCMCModel at 0x7f7479c0cda0>,\n",
       " 'Quintana Roo': <__main__.MCMCModel at 0x7f7479fe8860>,\n",
       " 'Sinaloa': <__main__.MCMCModel at 0x7f746a640780>,\n",
       " 'Tabasco': <__main__.MCMCModel at 0x7f7465c8f0f0>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baja California\n",
      "Ciudad de México\n",
      "México\n",
      "Quintana Roo\n",
      "Sinaloa\n",
      "Tabasco\n"
     ]
    }
   ],
   "source": [
    "# Combinar tablas\n",
    "Tab = pd.DataFrame()\n",
    "for k in modelos.keys():\n",
    "    print(k)\n",
    "    m1 = modelos[k]\n",
    "    tab = df_from_model(m1)\n",
    "    tab = tab.droplevel(0)\n",
    "    tab = tab.reset_index()\n",
    "    tab['estado'] = k\n",
    "    \n",
    "    Tab = pd.concat([Tab, tab])\n",
    "Tab['fecha_estimado'] = date.today().isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = dir_estimado + '/rt_live_estimados.csv'\n",
    "Tab.to_csv(archivo, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inicio = confirmed_to_onset(casos.positives, p_retraso)\n",
    "# # inicio = sintomas.positives\n",
    "# ajustados, p_retraso_acumulado = adjust_onset_for_right_censorship(inicio, p_retraso)\n",
    "# # ajustados\n",
    "# ii = ajustados.isin([np.nan, np.inf,-np.inf])\n",
    "# p_retraso_acumulado = p_retraso_acumulado[~ii]\n",
    "# m1 = MCMCModel('MX', inicio[~ii], p_retraso_acumulado).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = df_from_model(m1)\n",
    "# results = results.droplevel(0)\n",
    "# results['mean']\n",
    "# results = results.reset_index()\n",
    "# results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot_date(results['date'], results['median'], linestyle = \"-\", lw=2,markevery=1)\n",
    "# plt.fill_between(results.date,results['lower_90'].values, results['upper_90'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ax.plot(result['median'],\n",
    "#             marker='o',\n",
    "#             markersize=4,\n",
    "#             markerfacecolor='w',\n",
    "#             lw=1,\n",
    "#             c=c,\n",
    "#             markevery=2)\n",
    "#     ax.fill_between(\n",
    "#         result.index,\n",
    "#         result['lower_90'].values,\n",
    "#         result['upper_90'].values,\n",
    "#         color=ci,\n",
    "#         lw=0)\n",
    "\n",
    "# plt.plot(results['median'],\n",
    "#         marker='o',\n",
    "#             markersize=4,\n",
    "#             markerfacecolor='w',\n",
    "#             lw=1,\n",
    "#             markevery=2)\n",
    "# plt.fill_between(results.index,results['lower_90'].values, results['upper_90'].values)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.fill_between?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results.index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
